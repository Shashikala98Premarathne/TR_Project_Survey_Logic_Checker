{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4902f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# BCS Survey Logic Checker (with row-level details)\n",
    "# ==========================================================\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import streamlit as st\n",
    "import json\n",
    "import csv\n",
    "from io import BytesIO\n",
    "import io\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# App setup + theme\n",
    "# -------------------------------------------------------------------\n",
    "st.set_page_config(page_title=\"BCS Survey Logic Checker\", layout=\"wide\")\n",
    "\n",
    "def set_background_solid(main=\"#F4EB89\", sidebar=\"#EEEFF3\"):\n",
    "    st.markdown(f\"\"\"\n",
    "    <style>\n",
    "      [data-testid=\"stAppViewContainer\"],\n",
    "      [data-testid=\"stAppViewContainer\"] .main,\n",
    "      [data-testid=\"stAppViewContainer\"] .block-container {{\n",
    "        background-color: {main} !important;\n",
    "      }}\n",
    "      [data-testid=\"stSidebar\"],\n",
    "      [data-testid=\"stSidebar\"] > div,\n",
    "      [data-testid=\"stSidebar\"] .block-container {{\n",
    "        background-color: {sidebar} !important;\n",
    "      }}\n",
    "      header[data-testid=\"stHeader\"] {{ background: transparent; }}\n",
    "      [data-testid=\"stDataFrame\"],\n",
    "      [data-testid=\"stTable\"] {{ background-color: transparent !important; }}\n",
    "    </style>\n",
    "    \"\"\", unsafe_allow_html=True)\n",
    "\n",
    "set_background_solid()\n",
    "st.title(\"ðŸ“Š BCS Survey Logic Checker\")\n",
    "st.caption(\"This tool is specifically designed for BCS Thailand/Taiwan. Identified mismatches will be highlighted in the deliverables.\")\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# File helpers\n",
    "# -------------------------------------------------------------------\n",
    "COMMON_ENCODINGS = [\"utf-8\", \"utf-8-sig\", \"cp1252\", \"latin-1\"]\n",
    "ZIP_SIGNATURES = (b\"PK\\x03\\x04\", b\"PK\\x05\\x06\", b\"PK\\x07\\x08\")\n",
    "\n",
    "def _sniff_sep(sample_text: str) -> str:\n",
    "    try:\n",
    "        dialect = csv.Sniffer().sniff(sample_text[:4096], delimiters=\",;\\t|\")\n",
    "        return dialect.delimiter\n",
    "    except Exception:\n",
    "        return \",\"\n",
    "\n",
    "def _norm_delim(sel: str) -> str:\n",
    "    return {\"\\\\t\": \"\\t\"}.get(sel, sel)\n",
    "\n",
    "def read_any_table(uploaded_file, enc_override=\"auto\", delim_override=\"auto\", skip_bad=True) -> pd.DataFrame:\n",
    "    name = (uploaded_file.name or \"\").lower()\n",
    "    raw = uploaded_file.read()\n",
    "\n",
    "    if raw.startswith(ZIP_SIGNATURES) or name.endswith((\".xlsx\", \".xls\")):\n",
    "        uploaded_file.seek(0)\n",
    "        return pd.read_excel(uploaded_file)\n",
    "\n",
    "    encodings = COMMON_ENCODINGS if enc_override == \"auto\" else [enc_override]\n",
    "    for enc_try in encodings:\n",
    "        try:\n",
    "            text = raw.decode(enc_try, errors=\"strict\")\n",
    "            sep = _sniff_sep(text) if delim_override == \"auto\" else _norm_delim(delim_override)\n",
    "            kwargs = dict(encoding=enc_try, sep=sep, engine=\"python\")\n",
    "            if skip_bad:\n",
    "                kwargs[\"on_bad_lines\"] = \"skip\"\n",
    "            return pd.read_csv(BytesIO(raw), **kwargs)\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "    sep = \",\" if delim_override == \"auto\" else _norm_delim(delim_override)\n",
    "    kwargs = dict(encoding=\"latin-1\", sep=sep, engine=\"python\")\n",
    "    if skip_bad:\n",
    "        kwargs[\"on_bad_lines\"] = \"skip\"\n",
    "    return pd.read_csv(BytesIO(raw), **kwargs)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Sidebar upload\n",
    "# -------------------------------------------------------------------\n",
    "with st.sidebar:\n",
    "    st.header(\"Input\")\n",
    "    data_file = st.file_uploader(\"Current wave data\", type=[\"csv\", \"xlsx\", \"xls\"])\n",
    "    rules_file = st.file_uploader(\"Optional: custom rules JSON\", type=[\"json\"])\n",
    "    rules = json.load(rules_file) if rules_file else None\n",
    "\n",
    "    st.markdown(\"---\")\n",
    "    st.subheader(\"Parser overrides\")\n",
    "    enc = st.selectbox(\"Encoding\", [\"auto\", \"utf-8\", \"utf-8-sig\", \"cp1252\", \"latin-1\"], index=0)\n",
    "    delim = st.selectbox(\"Delimiter\", [\"auto\", \",\", \";\", \"\\\\t\", \"|\"], index=0)\n",
    "    skip_bad = st.checkbox(\"Skip bad lines\", value=True)\n",
    "\n",
    "if not data_file:\n",
    "    st.info(\"Upload a CSV/XLSX to begin.\")\n",
    "    st.stop()\n",
    "\n",
    "try:\n",
    "    data_file.seek(0)\n",
    "    df = read_any_table(data_file, enc_override=enc, delim_override=delim, skip_bad=skip_bad)\n",
    "except Exception as e:\n",
    "    st.error(f\"Failed to read file: {e}\")\n",
    "    st.stop()\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Clean null tokens\n",
    "# -------------------------------------------------------------------\n",
    "df.replace(\n",
    "    {\"#NULL!\": np.nan, \"NULL\": np.nan, \"null\": np.nan, \"NaN\": np.nan, \"nan\": np.nan,\n",
    "     \"\": np.nan, \"na\": np.nan, \"N/A\": np.nan, \"n/a\": np.nan},\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Rules list (global only)\n",
    "# -------------------------------------------------------------------\n",
    "SURVEY_RULES = {\n",
    "    1: \"Main brand must exist\",\n",
    "    2: \"Quota make autocoded\",\n",
    "    3: \"Company position requires OE if 98\",\n",
    "    4: \"Fleet size numeric (0â€“99999), terminate if 0\",\n",
    "    5: \"Last purchase required if S3>0\",\n",
    "    6: \"Usage single brand â†’ main_brand must match\",\n",
    "    10: \"Quota make satisfaction set required\",\n",
    "    11: \"Truck defects â†’ require OE\",\n",
    "    12: \"Volvo quota â†’ require satisfaction & dissatisfaction comments\",\n",
    "    13: \"Barriers â†’ require follow-ups\",\n",
    "    14: \"Transport type=98 â†’ require OE\",\n",
    "    15: \"Quota make in Volvo group â†’ require operation range\",\n",
    "    16: \"System fields (region, country, survey_year) required\",\n",
    "}\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Check engine (row-level)\n",
    "# -------------------------------------------------------------------\n",
    "digest = []\n",
    "detailed = []\n",
    "\n",
    "def add_issue(rule_id, msg, idx=None):\n",
    "    digest.append((rule_id, msg))\n",
    "    if idx is not None:\n",
    "        detailed.append((idx, rule_id, msg))\n",
    "\n",
    "# Rule 1 â€“ main_brand\n",
    "if \"main_brand\" not in df.columns:\n",
    "    add_issue(1, \"Missing main_brand column\")\n",
    "else:\n",
    "    if df[\"main_brand\"].isna().any():\n",
    "        bad = df[df[\"main_brand\"].isna()].index\n",
    "        for i in bad: add_issue(1, \"main_brand missing\", i)\n",
    "\n",
    "# Rule 2 â€“ quota_make\n",
    "if \"quota_make\" not in df.columns:\n",
    "    add_issue(2, \"Missing quota_make column\")\n",
    "elif \"main_brand\" in df.columns:\n",
    "    bad = df[\"quota_make\"].astype(str) != df[\"main_brand\"].astype(str)\n",
    "    for i in df[bad].index: add_issue(2, \"quota_make â‰  main_brand\", i)\n",
    "\n",
    "# Rule 3 â€“ company_position\n",
    "if \"company_position\" not in df.columns:\n",
    "    add_issue(3, \"Missing company_position\")\n",
    "else:\n",
    "    if (df[\"company_position\"] == 98).any():\n",
    "        if \"company_position_other_specify\" not in df.columns:\n",
    "            for i in df[df[\"company_position\"]==98].index:\n",
    "                add_issue(3, \"Missing OE for company_position=98\", i)\n",
    "\n",
    "# Rule 4 â€“ fleet size\n",
    "if \"n_heavy_duty_trucks\" not in df.columns:\n",
    "    add_issue(4, \"Missing n_heavy_duty_trucks\")\n",
    "else:\n",
    "    vals = pd.to_numeric(df[\"n_heavy_duty_trucks\"], errors=\"coerce\")\n",
    "    for i in df[vals.isna()].index: add_issue(4, \"Invalid numeric S3\", i)\n",
    "    for i in df[(vals < 0) | (vals > 99999)].index: add_issue(4, \"S3 out of range\", i)\n",
    "    for i in df[vals==0].index: add_issue(4, \"S3=0 (terminate)\", i)\n",
    "\n",
    "# Rule 5 â€“ last_purchase_hdt\n",
    "if \"last_purchase_hdt\" not in df.columns:\n",
    "    add_issue(5, \"Missing last_purchase_hdt\")\n",
    "\n",
    "# Rule 6 â€“ usage vs main_brand\n",
    "usage_cols = [c for c in df.columns if c.startswith(\"usage_\")]\n",
    "if usage_cols and \"main_brand\" in df.columns and \"A2b\" in df.columns:\n",
    "    one_brand = df[usage_cols].sum(axis=1) == 1\n",
    "    bad = one_brand & (df[\"A2b\"].astype(str) != df[\"main_brand\"].astype(str))\n",
    "    for i in df[bad].index: add_issue(6, \"A2b â‰  single usage brand\", i)\n",
    "\n",
    "# Rule 10 â€“ quota satisfaction set\n",
    "quota_checks = [\"overall_satisfaction\",\"likelihood_choose_brand\",\"likelihood_choose_workshop\",\"preference_strength\",\"overall_rating_truck\"]\n",
    "for c in quota_checks:\n",
    "    if c not in df.columns:\n",
    "        add_issue(10, f\"Missing {c}\")\n",
    "\n",
    "# Rule 11 â€“ truck defects\n",
    "if \"truck_defects\" in df.columns and (df[\"truck_defects\"]==1).any():\n",
    "    if \"truck_defects_other_specify\" not in df.columns:\n",
    "        for i in df[df[\"truck_defects\"]==1].index:\n",
    "            add_issue(11, \"Missing OE for truck_defects=1\", i)\n",
    "\n",
    "# Rule 12 â€“ Volvo quota\n",
    "if \"quota_make\" in df.columns and (df[\"quota_make\"].astype(str)==\"38\").any():\n",
    "    for c in [\"satisfaction_comments\",\"dissatisfaction_comments\"]:\n",
    "        if c not in df.columns:\n",
    "            for i in df[df[\"quota_make\"].astype(str)==\"38\"].index:\n",
    "                add_issue(12, f\"Missing {c} for Volvo\", i)\n",
    "\n",
    "# Rule 13 â€“ Barriers\n",
    "if \"reasons_not_consider_volvo\" in df.columns:\n",
    "    for follow, col in [(\"a\",\"a_barriers_follow_up\"),(\"b\",\"b_barriers_follow_up\"),(\"c\",\"c_barriers_follow_up\")]:\n",
    "        if col not in df.columns:\n",
    "            for i in df.index: add_issue(13, f\"Missing {col}\", i)\n",
    "\n",
    "# Rule 14 â€“ transport_type OE\n",
    "if \"transport_type\" in df.columns and (df[\"transport_type\"]==98).any():\n",
    "    if \"transport_type_other_specify\" not in df.columns:\n",
    "        for i in df[df[\"transport_type\"]==98].index:\n",
    "            add_issue(14, \"Missing OE for transport_type=98\", i)\n",
    "\n",
    "# Rule 15 â€“ Volvo group operation range\n",
    "if \"quota_make\" in df.columns and df[\"quota_make\"].astype(str).isin([\"38\",\"31\",\"23\",\"9\"]).any():\n",
    "    if \"operation_range_volvo_hdt\" not in df.columns:\n",
    "        for i in df[df[\"quota_make\"].astype(str).isin([\"38\",\"31\",\"23\",\"9\"])].index:\n",
    "            add_issue(15, \"Missing operation_range_volvo_hdt\", i)\n",
    "\n",
    "# Rule 16 â€“ system fields\n",
    "for sysc in [\"region\",\"country\",\"survey_year\"]:\n",
    "    if sysc not in df.columns:\n",
    "        add_issue(16, f\"Missing {sysc}\")\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Prepare outputs\n",
    "# -------------------------------------------------------------------\n",
    "digest_df = pd.DataFrame(digest, columns=[\"RuleID\",\"Issue\"]).drop_duplicates()\n",
    "detailed_df = pd.DataFrame(detailed, columns=[\"RowID\",\"RuleID\",\"Issue\"])\n",
    "\n",
    "st.subheader(\"Survey Logic Issues\")\n",
    "if digest_df.empty:\n",
    "    st.success(\"âœ… No issues found â€“ dataset follows survey logic.\")\n",
    "else:\n",
    "    st.dataframe(digest_df, use_container_width=True)\n",
    "\n",
    "    # Export to Excel\n",
    "    out = io.BytesIO()\n",
    "    with pd.ExcelWriter(out, engine=\"xlsxwriter\") as writer:\n",
    "        digest_df.to_excel(writer, index=False, sheet_name=\"Digest\")\n",
    "        detailed_df.to_excel(writer, index=False, sheet_name=\"Detailed\")\n",
    "    st.download_button(\n",
    "        \"ðŸ“¥ Download Issues (Excel)\",\n",
    "        data=out.getvalue(),\n",
    "        file_name=\"survey_logic_issues.xlsx\",\n",
    "        mime=\"application/vnd.openxmlformats-officedocument.spreadsheetml.sheet\"\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
